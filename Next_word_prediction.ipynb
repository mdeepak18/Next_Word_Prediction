{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next_word_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rqgvFjkLZ8Y"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import string\n",
        "import requests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc0GDMBHfFZh"
      },
      "source": [
        "response = requests.get('https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt')\n",
        "#response.text[:1500]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg3Z6gxjfb0Z"
      },
      "source": [
        "data = response.text.split('\\n')\n",
        "data = data[253:]\n",
        "#len(data)\n",
        "data = \" \".join(data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUN5jzkbfibQ",
        "outputId": "d0f0d0c6-4f9b-41fe-cab6-a949cf7e3677"
      },
      "source": [
        "def clean_text(doc):\n",
        "  tokens = doc.split()\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "tokens = clean_text(data)\n",
        "print(tokens[:50])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['from', 'fairest', 'creatures', 'we', 'desire', 'increase', 'that', 'thereby', 'beautys', 'rose', 'might', 'never', 'die', 'but', 'as', 'the', 'riper', 'should', 'by', 'time', 'decease', 'his', 'tender', 'heir', 'might', 'bear', 'his', 'memory', 'but', 'thou', 'contracted', 'to', 'thine', 'own', 'bright', 'eyes', 'feedst', 'thy', 'lights', 'flame', 'with', 'selfsubstantial', 'fuel', 'making', 'a', 'famine', 'where', 'abundance', 'lies', 'thy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC-7JSv4E0lU",
        "outputId": "fa342363-3de1-4caf-939e-fc8986c0b6ef"
      },
      "source": [
        "#len(tokens)\n",
        "len(set(tokens))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67z7QSKiHXSk"
      },
      "source": [
        "Let's use a set of 50 words to predict the 51st word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIAw37opHb7p",
        "outputId": "0fd6f75a-af44-43f5-c8c2-b0ee1ad177e2"
      },
      "source": [
        "length = 50 + 1\n",
        "lines = []\n",
        "\n",
        "for i in range(length, len(tokens)):\n",
        "  seq = tokens[i-length:i]\n",
        "  line = ' '.join(seq)\n",
        "  lines.append(line)\n",
        "  if i > 200000:\n",
        "    break\n",
        "\n",
        "print(len(lines))\n",
        "#lines[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "199951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYSycJMSO1oN",
        "outputId": "929d4a38-44ba-4226-a920-bf64c9aa9cb9"
      },
      "source": [
        "type(lines)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfamLfSnICU5"
      },
      "source": [
        "Building the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8R1Ph7AIGBh"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OqvOisMHr9Q"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N2GNSCkItLr"
      },
      "source": [
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:,-1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-ExFMafJUBa",
        "outputId": "9f4ad3a7-88cc-4ab6-8f07-4dff95630b2e"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]\n",
        "seq_length"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXS_hNIfJ01x"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiyACEa7JxUA",
        "outputId": "b6d1b270-87b4-4a2a-d4c0-38b924078f0f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            650450    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 13009)             1313909   \n",
            "=================================================================\n",
            "Total params: 2,115,259\n",
            "Trainable params: 2,115,259\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbPEVnY4Kn1C",
        "outputId": "d21b3183-94d5-465a-9b45-8a419d4a56fb"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X, y, batch_size = 256, epochs = 100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "782/782 [==============================] - 59s 65ms/step - loss: 6.8741 - accuracy: 0.0309\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 6.4981 - accuracy: 0.0445\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 48s 61ms/step - loss: 6.2776 - accuracy: 0.0623\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 6.0934 - accuracy: 0.0751\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 5.9539 - accuracy: 0.0849\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 5.8356 - accuracy: 0.0931\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 5.7259 - accuracy: 0.1004\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 5.6289 - accuracy: 0.1055\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 5.5398 - accuracy: 0.1089\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 5.4516 - accuracy: 0.1126\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 5.3649 - accuracy: 0.1158\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 5.2810 - accuracy: 0.1182\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 5.2012 - accuracy: 0.1214\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 5.1233 - accuracy: 0.1243\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 5.0488 - accuracy: 0.1265\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 4.9760 - accuracy: 0.1291\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 4.9106 - accuracy: 0.1322\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 4.8449 - accuracy: 0.1366\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 4.7831 - accuracy: 0.1407\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.7255 - accuracy: 0.1456\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.6727 - accuracy: 0.1499\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.6244 - accuracy: 0.1536\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.5779 - accuracy: 0.1584\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.5331 - accuracy: 0.1622\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.4918 - accuracy: 0.1671\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.4540 - accuracy: 0.1706\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.4160 - accuracy: 0.1756\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 4.3801 - accuracy: 0.1794\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.3468 - accuracy: 0.1827\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.3152 - accuracy: 0.1871\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.2858 - accuracy: 0.1894\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.2528 - accuracy: 0.1936\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.2225 - accuracy: 0.1973\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 4.1953 - accuracy: 0.2010\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 4.1671 - accuracy: 0.2038\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 4.1394 - accuracy: 0.2080\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 4.1142 - accuracy: 0.2104\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 4.0887 - accuracy: 0.2144\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.0649 - accuracy: 0.2167\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.0400 - accuracy: 0.2194\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 4.0164 - accuracy: 0.2231\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.9939 - accuracy: 0.2260\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.9691 - accuracy: 0.2297\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.9480 - accuracy: 0.2318\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.9236 - accuracy: 0.2345\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 3.9027 - accuracy: 0.2383\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.8805 - accuracy: 0.2412\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.8609 - accuracy: 0.2438\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.8382 - accuracy: 0.2465\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.8196 - accuracy: 0.2493\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.7990 - accuracy: 0.2523\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.7772 - accuracy: 0.2549\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.7583 - accuracy: 0.2578\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.7389 - accuracy: 0.2603\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.7208 - accuracy: 0.2627\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.7002 - accuracy: 0.2647\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 3.6814 - accuracy: 0.2680\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.6618 - accuracy: 0.2706\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.6440 - accuracy: 0.2734\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.6254 - accuracy: 0.2771\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.6064 - accuracy: 0.2778\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.5855 - accuracy: 0.2812\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.5704 - accuracy: 0.2835\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.5501 - accuracy: 0.2860\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.5355 - accuracy: 0.2886\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.5154 - accuracy: 0.2926\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.5001 - accuracy: 0.2944\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.4822 - accuracy: 0.2955\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.4654 - accuracy: 0.2989\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 3.4481 - accuracy: 0.3015\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.4329 - accuracy: 0.3029\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.4142 - accuracy: 0.3072\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.4001 - accuracy: 0.3087\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3833 - accuracy: 0.3117\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3677 - accuracy: 0.3140\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3526 - accuracy: 0.3169\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3375 - accuracy: 0.3177\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3199 - accuracy: 0.3214\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.3075 - accuracy: 0.3232\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.2921 - accuracy: 0.3255\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 3.2784 - accuracy: 0.3278\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 3.2602 - accuracy: 0.3303\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.2477 - accuracy: 0.3323\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.2317 - accuracy: 0.3340\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.2185 - accuracy: 0.3362\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.2049 - accuracy: 0.3391\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1907 - accuracy: 0.3406\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1767 - accuracy: 0.3430\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1631 - accuracy: 0.3455\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1477 - accuracy: 0.3474\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1367 - accuracy: 0.3494\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1212 - accuracy: 0.3530\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.1083 - accuracy: 0.3546\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 46s 58ms/step - loss: 3.0961 - accuracy: 0.3562\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.0860 - accuracy: 0.3581\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.0689 - accuracy: 0.3608\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 3.0549 - accuracy: 0.3632\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.0450 - accuracy: 0.3637\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.0316 - accuracy: 0.3669\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 46s 59ms/step - loss: 3.0238 - accuracy: 0.3679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f0f24d210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kNoHH2UAK1Ri",
        "outputId": "cd791e38-4e17-4933-ba28-a42cb5841018"
      },
      "source": [
        "seed_text=lines[12343]\n",
        "seed_text"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'home of love if i have ranged like him that travels i return again just to the time not with the time exchanged so that my self bring water for my stain never believe though in my nature reigned all frailties that besiege all kinds of blood that it could so'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gkKr-vaS0L1"
      },
      "source": [
        "def generate_text_seq(model, tokenizer, text_seq_length, seed_text, n_words):\n",
        "  text = []\n",
        "\n",
        "  for _ in range(n_words):\n",
        "    encoded = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen = text_seq_length, truncating='pre')\n",
        "\n",
        "    y_predict = model.predict_classes(encoded)\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == y_predict:\n",
        "        predicted_word = word\n",
        "        break\n",
        "    seed_text = seed_text + ' ' + predicted_word\n",
        "    text.append(predicted_word)\n",
        "  return ' '.join(text)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "SFlEeBxXS9_b",
        "outputId": "d0098e91-eb7f-43ad-8323-8a4927a85742"
      },
      "source": [
        "generate_text_seq(model, tokenizer, seq_length, seed_text, 100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'preposterously be stained to leave to fail and by the fatness of our senseless judgment and ourself and knewst the broken world the virginal infectious second servant of the world and let me hear of him and about the consuls worthiness of the rangd of them brats in a perpetual dulness let their hast been within and we in solemn hours qualifies the bravery of the kings that milks and does the prisond walls tables therein and lack extinct in take and feeding doth eat triumphant merit more strong horrible shaming a crooked sentence of barren senators and desprate creature'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}